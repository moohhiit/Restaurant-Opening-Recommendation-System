{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4BNfdAUzUo7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import chain\n",
        "import random\n",
        "from  sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "area_population = pd.read_csv('/content/indian.csv')\n",
        "area_population.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DBItfR7Nz_X1",
        "outputId": "50851f48-1e33-4607-b8b8-0748b0954b3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Rank', 'City', 'Population(2011)', 'Population(2001)',\n",
              "       'State or union territory'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zomato = pd.read_csv('/content/zomato.csv', encoding='latin1')\n"
      ],
      "metadata": {
        "id": "zKnisCum1fGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zomato_ind = zomato[zomato['Country Code'] == 1]\n",
        "zomato_ind.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXlFP9U63pep",
        "outputId": "faa277c8-1c0b-48b9-8217-b923b04de213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Restaurant ID', 'Restaurant Name', 'Country Code', 'City', 'Address',\n",
              "       'Locality', 'Locality Verbose', 'Longitude', 'Latitude', 'Cuisines',\n",
              "       'Average Cost for two', 'Currency', 'Has Table booking',\n",
              "       'Has Online delivery', 'Is delivering now', 'Switch to order menu',\n",
              "       'Price range', 'Aggregate rating', 'Rating color', 'Rating text',\n",
              "       'Votes'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nnLLJEgv4jlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "restaurant_data = zomato_ind[['Restaurant Name' , 'City' , 'Cuisines' , 'Longitude' ,'Latitude' ,'Aggregate rating' , 'Price range' , 'Has Online delivery']]"
      ],
      "metadata": {
        "id": "MBOmvrkl2UKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graphics_data = area_population[['City' ,'Population(2011)']]\n",
        "graphics_data['Avg_Income'] = np.random.randint(1000, 10001, size=len(area_population))\n",
        "graphics_data['Youth_Percentage'] = np.round(np.random.rand(len(area_population)), 2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "63RVELKZ3hTi",
        "outputId": "bf838a6a-d8ea-4993-f2a5-aa013b3b5b44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3140965880.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  graphics_data['Avg_Income'] = np.random.randint(1000, 10001, size=len(area_population))\n",
            "/tmp/ipython-input-3140965880.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  graphics_data['Youth_Percentage'] = np.round(np.random.rand(len(area_population)), 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FRPqqWW--YHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "restaurant_data_cuisines = restaurant_data['Cuisines'].apply(lambda x :[c.strip() for c in x.split(',')])\n",
        "\n",
        "cuisine_pool = list(set(chain.from_iterable(restaurant_data_cuisines)))\n"
      ],
      "metadata": {
        "id": "WfzBPx1S-hrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cities = pd.read_csv('/content/Indian Cities Database.csv')"
      ],
      "metadata": {
        "id": "Uf0qVUhN9RjJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "a2cb1cf4-b46e-4dea-9dfa-1b2d49dd7b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Indian Cities Database.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3682376660.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Indian Cities Database.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Indian Cities Database.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "competitor_data = pd.DataFrame({\n",
        "    'City': cities['City'],\n",
        "    'Total_Restaurants': np.random.randint(100 , 1500 , size= len(cities)),\n",
        "    'Avg_Rating': np.random.randint(1 , 6 , size=len(cities)),\n",
        "    'Popular_Cuisines': [random.sample(cuisine_pool, 2 )for _ in range(len(cities))]\n",
        "})\n"
      ],
      "metadata": {
        "id": "CgD03FTW7siR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location_data = pd.DataFrame({\n",
        "    'City': cities['City'],\n",
        "    'Foot_Traffic_Index': np.random.randint(1 , 101 , size=len(cities)),\n",
        "    'Avg_Rent_per_sqft': np.random.randint(10 , 101 , size=len(cities))\n",
        "})"
      ],
      "metadata": {
        "id": "eaabqW1CAwSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "merge tha Datasets for training"
      ],
      "metadata": {
        "id": "OkMadV0uGu0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "finaldata = restaurant_data.merge(graphics_data , left_on='City' , right_on='City' )\n",
        "finaldata = finaldata.merge(location_data  , left_on='City' , right_on='City' )\n",
        "finaldata = finaldata.merge(competitor_data  , left_on='City' , right_on='City' )\n",
        "finaldata['Review_Count'] = np.random.randint(20 , 500 , size= len(finaldata))\n"
      ],
      "metadata": {
        "id": "pBCsph_7A79f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_VbQJGCYO7GC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "finaldata['Population(2011)'] = finaldata['Population(2011)'].str.replace(r'\\D', '', regex=True).astype(int)\n",
        "# finaldata['Population(2011)']"
      ],
      "metadata": {
        "id": "W4xO848PJQHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finaldata['Population(2011)'].dtypes"
      ],
      "metadata": {
        "id": "YSUL-_lQNY0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finaldata.columns"
      ],
      "metadata": {
        "id": "4EwP_HTJPMNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Competition Index\n",
        "finaldata['Competition_Index'] = finaldata['Total_Restaurants'] / finaldata['Population(2011)']\n",
        "\n",
        "# Affordability\n",
        "finaldata['Affordability'] = finaldata['Avg_Income'] / finaldata['Avg_Rent_per_sqft']\n",
        "\n",
        "# Popularity Index\n",
        "finaldata['Popularity_Index'] = finaldata['Aggregate rating'] * finaldata['Review_Count'] / finaldata['Total_Restaurants']\n",
        "\n",
        "# Target Score (for supervised learning)\n",
        "finaldata['Success_Score'] = (\n",
        "    finaldata['Aggregate rating'] * 0.4 +\n",
        "    (finaldata['Review_Count'] / finaldata['Review_Count'].max()) * 0.2 +\n",
        "    (finaldata['Foot_Traffic_Index'] / 100) * 0.2 +\n",
        "    (finaldata['Affordability'] / finaldata['Affordability'].max()) * 0.2\n",
        ")\n"
      ],
      "metadata": {
        "id": "lV6bLplPKMjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finaldata.columns"
      ],
      "metadata": {
        "id": "h2-t8qaQMnzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finaldata.head()"
      ],
      "metadata": {
        "id": "P2beOBn-Qgqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finaldata = pd.get_dummies(finaldata, columns=['Cuisine'], drop_first=True)\n",
        "finaldata.dtypes\n"
      ],
      "metadata": {
        "id": "xLXF9C1aQjG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finaldata = pd.get_dummies(finaldata, columns=['Cuisines'], drop_first=True)"
      ],
      "metadata": {
        "id": "SFS2LiogQ1-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finaldata.columns"
      ],
      "metadata": {
        "id": "ucXDBoLpRjwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['Foot_Traffic_Index', 'Competition_Index', 'Affordability', 'Youth_Percentage', 'Price range']"
      ],
      "metadata": {
        "id": "Q8vX0eEuR0i_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features += [col for col in finaldata.columns if 'Cuisine_' in col]"
      ],
      "metadata": {
        "id": "Ru8eUKJYbs5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = finaldata[features]\n",
        "y = finaldata['Success_Score']"
      ],
      "metadata": {
        "id": "8kFEmr9Ob1KF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "d3eqaOFgiCPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L3USrHcuiqLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"R² Score:\", r2_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "lT_d3a-7isYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User inputs\n",
        "user_location = 'Lucknow'\n",
        "user_cuisine = 'Indian'\n",
        "\n",
        "# Extract location info\n",
        "loc_info = location_data[location_data['City'] == user_location].iloc[0]\n",
        "demo_info = graphics_data[graphics_data['City'] == user_location].iloc[0]\n",
        "comp_info = competitor_data[competitor_data['City'] == user_location].iloc[0]\n",
        "\n",
        "# Feature calculations\n",
        "foot_traffic = loc_info['Foot_Traffic_Index']\n",
        "avg_rent = loc_info['Avg_Rent_per_sqft']\n",
        "population = demo_info['Population(2011)']\n",
        "avg_income = demo_info['Avg_Income']\n",
        "youth_percent = demo_info['Youth_Percentage']\n",
        "total_restaurants = comp_info['Total_Restaurants']\n",
        "\n",
        "competition_index = total_restaurants / population\n",
        "affordability = avg_income / avg_rent\n",
        "\n",
        "# Default assumptions for a new restaurant\n",
        "rating = 4.0\n",
        "review_count = 50\n",
        "price_level = '₹₹'\n",
        "price_mapping = {'₹': 1, '₹₹': 2, '₹₹₹': 3}\n",
        "price_level_num = price_mapping[price_level]\n",
        "\n",
        "# Create feature vector\n",
        "features_dict = {\n",
        "    'Foot_Traffic_Index': foot_traffic,\n",
        "    'Competition_Index': competition_index,\n",
        "    'Affordability': affordability,\n",
        "    'Youth_Percentage': youth_percent,\n",
        "    'Price_Level_Num': price_level_num\n",
        "}\n",
        "\n",
        "# One-hot encoding for cuisine\n",
        "for col in X.columns:\n",
        "    if 'Cuisine_' in col:\n",
        "        features_dict[col] = 1 if col == f'Cuisine_{user_cuisine}' else 0\n",
        "\n",
        "# Convert to DataFrame\n",
        "X_new = pd.DataFrame([features_dict])\n",
        "\n"
      ],
      "metadata": {
        "id": "b3XHZqOSi0kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NRYS5Q1ljcOF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}